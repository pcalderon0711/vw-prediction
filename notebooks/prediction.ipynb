{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempts on Success Prediction from VW Post Content\n",
    "\n",
    "There are two approaches we can do to try to predict success: regression and classification.\n",
    "\n",
    "## 1. Regression\n",
    "X = similarity of a post with the dimensions\n",
    "\n",
    "y = success score\n",
    "\n",
    "We will try two models: Linear Regression and a Fully-Connected Neural Network\n",
    "\n",
    "## 2. Classification\n",
    "\n",
    "### 2.1 Simple Models\n",
    "X = similarity of a post with the dimensions\n",
    "\n",
    "y = 0/1 (1 if post is successful, i.e. success > 208, the mean of the data after removing top 10% and bottom 10%)\n",
    "\n",
    "We will try logistic regression and FCNN.\n",
    "\n",
    "### 2.2 More Complicated Models\n",
    "We will try two LSTM architectures in this part. We cut each post to the first 50 tokens.\n",
    "\n",
    "**LSTM1** : Use the embedding vectors of each the words as input to the LSTM, then pass into a sequence of fully connected layers.\n",
    "\n",
    "**LSTM2** : Use embedding vectors as input to the LSTM, concatenate dimension similarity vector with the output of the LSTM, then pass the concatenated vector into a sequence of fully connected layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator, re, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "from neurotools.io.files import load_embedding_model\n",
    "from neurotools.io.gdrive import download_sheets_doc\n",
    "from neurotools.plot import figure\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from neurotools.language.simple_tokenizer import SimpleTokenizer\n",
    "from wordcloud import WordCloud\n",
    "from googletrans import Translator\n",
    "import itertools\n",
    "import ast\n",
    "from neurotools.io.gdrive import download_sheets_doc\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, concatenate\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rc('font',family='Open Sans')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load tokenizer, embedding, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra characters read for pl\n",
      "Stopwords set read for pl\n",
      "Lemma lookup read for pl\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizer('pl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb, word2rank_dict = load_embedding_model('../../vw-impact/utils/pl_pl_commoncrawl_v3.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_average_vector(words, emb):\n",
    "    \"\"\"\n",
    "        Average the word vectors of a list of words.\n",
    "    \"\"\"\n",
    "    words_in_emb = [emb[word] for word in words if word in emb.vocab.keys() and word not in ['bezpieczeństwo', 'pistolet']]\n",
    "    return np.mean(words_in_emb, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_idf_map(documents):\n",
    "    tfidf = TfidfVectorizer(use_idf=True)\n",
    "    tfidf.fit_transform(documents)\n",
    "    word_to_idf = dict((x[0], tfidf.idf_[x[1]]) for x in sorted(tfidf.vocabulary_.items(), key=operator.itemgetter(1)))\n",
    "    return word_to_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_idf_weighted_average_vector(words, word_to_idf, emb):\n",
    "    \"\"\"\n",
    "        Average the idf-weighted word vectors of a list of words. (Map this function to every document)\n",
    "    \"\"\"\n",
    "    # only consider words IN embedding model and in TFIDF vectorizer\n",
    "    words = [word for word in words if word in word_to_idf.keys() and word in emb.vocab.keys() and word not in ['bezpieczeństwo', 'pistolet']]\n",
    "    weighted = [word_to_idf[word] * emb[word] for word in words]\n",
    "    return np.mean(weighted, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(a,b):\n",
    "    \"\"\"\n",
    "        Compute the cosine similarity of a and b.\n",
    "    \"\"\"\n",
    "    return np.dot(a,b) / ( (np.dot(a,a) **.5) * (np.dot(b,b) ** .5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_similarity_with_dimensions(row, dimensions):\n",
    "    \"\"\"\n",
    "        Get similarity of row's word vector and every dimension.\n",
    "        row : row of the movie dataframe\n",
    "        dimensions : dataframe containing Neuroflash dimensions\n",
    "    \"\"\"\n",
    "    for k in range(dimensions['dimension'].shape[0]):\n",
    "        name = str(dimensions['en_label'].iloc[k])\n",
    "        # define a new column for the cosine similarity of dimension k and the post text\n",
    "        row[name] = cosine_similarity(row['wv'], dimensions['dimension'].iloc[k])\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Regression using Lin Regression and MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vw = pd.read_csv('../processed/processed_volkswagenpolska.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vw = vw[['Trendy',\n",
    "       'Kind', 'Polite', 'Warm', 'Diligent', 'Blue_Collar', 'White_Collar',\n",
    "       'Protective', 'Serious', 'Funny', 'Pleasant', 'Beautiful', 'Alive',\n",
    "       'Above', 'Descriptive', 'Cheap', 'Expensive', 'Big', 'Small', 'Modern',\n",
    "       'Traditional', 'Appealing', 'Sustainable', 'Practical', 'Active',\n",
    "       'Easy', 'Trustworthy', 'Natural', 'Arts', 'Career', 'Family', 'Female',\n",
    "       'Male', 'Math', 'Science', 'Open', 'Cool', 'Likeable', 'Children',\n",
    "       'Community', 'Culture', 'Design', 'Innovative', 'Responsible',\n",
    "       'Extroverted', 'Fascination', 'Friendship', 'Functionality', 'Winner',\n",
    "       'Lifestyle', 'Music', 'New', 'Bargain', 'Power', 'Safety', 'Teaching',\n",
    "       'Technical', 'Valuable', 'Feel Good', 'Support', 'Inspire', 'Happiness',\n",
    "       'Celebrate', 'Meaningful', 'success']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vw = vw[~vw['Trendy'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = vw['success']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "retain = (y[~pd.qcut(y, 10, labels=range(10)).isin([0,9])]).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = vw.loc[retain,:].iloc[:,:-1]\n",
    "y = vw.loc[retain,:].iloc[:,-1]\n",
    "# logy = np.log(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11279695387314803"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.034201241371870195"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-64.0, 1344.0, -401.3974343887023, 258.1500786533325)"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAD5CAYAAADGMZVsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19f0555f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lr.predict(X_train).reshape(-1)- y_train.values, color='blue', label='train')\n",
    "plt.plot(lr.predict(X_test).reshape(-1)-y_test.values, color='red', label='test')\n",
    "plt.legend()\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206.30366900858704\n",
      "211.8785046728972\n"
     ]
    }
   ],
   "source": [
    "print(y_train.mean())\n",
    "print(y_test.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High residuals. Model did not generalize to the test set!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_shape = (X_train.shape[1],)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(8))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_44 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,353\n",
      "Trainable params: 2,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "1281/1281 [==============================] - 2s 2ms/step - loss: 54290.7075\n",
      "Epoch 2/250\n",
      "1281/1281 [==============================] - 0s 41us/step - loss: 53226.7251\n",
      "Epoch 3/250\n",
      "1281/1281 [==============================] - 0s 40us/step - loss: 51753.9687\n",
      "Epoch 4/250\n",
      "1281/1281 [==============================] - 0s 39us/step - loss: 49464.9914\n",
      "Epoch 5/250\n",
      "1281/1281 [==============================] - 0s 48us/step - loss: 46283.5251\n",
      "Epoch 6/250\n",
      "1281/1281 [==============================] - 0s 46us/step - loss: 42214.1269\n",
      "Epoch 7/250\n",
      "1281/1281 [==============================] - 0s 49us/step - loss: 37286.6825\n",
      "Epoch 8/250\n",
      "1281/1281 [==============================] - 0s 39us/step - loss: 32346.7834\n",
      "Epoch 9/250\n",
      "1281/1281 [==============================] - 0s 42us/step - loss: 27516.2589\n",
      "Epoch 10/250\n",
      "1281/1281 [==============================] - 0s 36us/step - loss: 25497.9089\n",
      "Epoch 11/250\n",
      "1281/1281 [==============================] - 0s 43us/step - loss: 24449.0477\n",
      "Epoch 12/250\n",
      "1281/1281 [==============================] - 0s 33us/step - loss: 24253.4585\n",
      "Epoch 13/250\n",
      "1281/1281 [==============================] - 0s 41us/step - loss: 23729.3816\n",
      "Epoch 14/250\n",
      "1281/1281 [==============================] - 0s 33us/step - loss: 23464.6343\n",
      "Epoch 15/250\n",
      "1281/1281 [==============================] - 0s 34us/step - loss: 22984.3092\n",
      "Epoch 16/250\n",
      "1281/1281 [==============================] - 0s 69us/step - loss: 23489.8534\n",
      "Epoch 17/250\n",
      "1281/1281 [==============================] - 0s 54us/step - loss: 22286.5433\n",
      "Epoch 18/250\n",
      "1281/1281 [==============================] - 0s 46us/step - loss: 23670.0946\n",
      "Epoch 19/250\n",
      "1281/1281 [==============================] - 0s 47us/step - loss: 23496.1511\n",
      "Epoch 20/250\n",
      "1281/1281 [==============================] - 0s 44us/step - loss: 23033.2288\n",
      "Epoch 21/250\n",
      "1281/1281 [==============================] - 0s 46us/step - loss: 23024.1080\n",
      "Epoch 22/250\n",
      "1281/1281 [==============================] - 0s 52us/step - loss: 21930.7579\n",
      "Epoch 23/250\n",
      "1281/1281 [==============================] - 0s 45us/step - loss: 22076.6334\n",
      "Epoch 24/250\n",
      "1281/1281 [==============================] - 0s 46us/step - loss: 22257.4119\n",
      "Epoch 25/250\n",
      "1281/1281 [==============================] - 0s 46us/step - loss: 21890.7679\n",
      "Epoch 26/250\n",
      "1281/1281 [==============================] - 0s 38us/step - loss: 21963.9560\n",
      "Epoch 27/250\n",
      "1281/1281 [==============================] - 0s 49us/step - loss: 22245.1858\n",
      "Epoch 28/250\n",
      "1281/1281 [==============================] - 0s 43us/step - loss: 21873.0176\n",
      "Epoch 29/250\n",
      "1281/1281 [==============================] - 0s 46us/step - loss: 23014.5952\n",
      "Epoch 30/250\n",
      "1281/1281 [==============================] - 0s 50us/step - loss: 22937.0006\n",
      "Epoch 31/250\n",
      "1281/1281 [==============================] - 0s 45us/step - loss: 22455.5793\n",
      "Epoch 32/250\n",
      "1281/1281 [==============================] - 0s 51us/step - loss: 22149.0010\n",
      "Epoch 33/250\n",
      "1281/1281 [==============================] - 0s 39us/step - loss: 21866.6983\n",
      "Epoch 34/250\n",
      "1281/1281 [==============================] - 0s 46us/step - loss: 21377.1965\n",
      "Epoch 35/250\n",
      "1281/1281 [==============================] - 0s 32us/step - loss: 21744.4310\n",
      "Epoch 36/250\n",
      "1281/1281 [==============================] - 0s 31us/step - loss: 22048.4326\n",
      "Epoch 37/250\n",
      "1281/1281 [==============================] - 0s 54us/step - loss: 22025.1224\n",
      "Epoch 38/250\n",
      "1281/1281 [==============================] - 0s 48us/step - loss: 22386.8478\n",
      "Epoch 39/250\n",
      "1281/1281 [==============================] - 0s 61us/step - loss: 21790.1402\n",
      "Epoch 40/250\n",
      "1281/1281 [==============================] - 0s 44us/step - loss: 21832.1997\n",
      "Epoch 41/250\n",
      "1281/1281 [==============================] - 0s 45us/step - loss: 21834.9339\n",
      "Epoch 42/250\n",
      "1281/1281 [==============================] - 0s 49us/step - loss: 20754.6568\n",
      "Epoch 43/250\n",
      "1281/1281 [==============================] - 0s 52us/step - loss: 21298.8029\n",
      "Epoch 44/250\n",
      "1281/1281 [==============================] - 0s 71us/step - loss: 21663.5405\n",
      "Epoch 45/250\n",
      "1281/1281 [==============================] - 0s 235us/step - loss: 21241.1068\n",
      "Epoch 46/250\n",
      "1281/1281 [==============================] - 0s 137us/step - loss: 21695.8566\n",
      "Epoch 47/250\n",
      "1281/1281 [==============================] - 0s 98us/step - loss: 21546.4705\n",
      "Epoch 48/250\n",
      "1281/1281 [==============================] - 0s 95us/step - loss: 21666.7475\n",
      "Epoch 49/250\n",
      "1281/1281 [==============================] - 0s 54us/step - loss: 20898.6500\n",
      "Epoch 50/250\n",
      "1281/1281 [==============================] - 0s 36us/step - loss: 20619.9238\n",
      "Epoch 51/250\n",
      "1281/1281 [==============================] - 0s 32us/step - loss: 21592.6277\n",
      "Epoch 52/250\n",
      "1281/1281 [==============================] - 0s 34us/step - loss: 20882.3289\n",
      "Epoch 53/250\n",
      "1281/1281 [==============================] - 0s 32us/step - loss: 21490.0125\n",
      "Epoch 54/250\n",
      "1281/1281 [==============================] - 0s 31us/step - loss: 21387.2082\n",
      "Epoch 55/250\n",
      "1281/1281 [==============================] - 0s 32us/step - loss: 20353.5556\n",
      "Epoch 56/250\n",
      "1281/1281 [==============================] - 0s 32us/step - loss: 20833.9639\n",
      "Epoch 57/250\n",
      "1281/1281 [==============================] - 0s 32us/step - loss: 21118.8810\n",
      "Epoch 58/250\n",
      "1281/1281 [==============================] - 0s 32us/step - loss: 20911.2100\n",
      "Epoch 59/250\n",
      "1281/1281 [==============================] - 0s 35us/step - loss: 21038.4819\n",
      "Epoch 60/250\n",
      "1281/1281 [==============================] - 0s 50us/step - loss: 21042.3897\n",
      "Epoch 61/250\n",
      "1281/1281 [==============================] - 0s 65us/step - loss: 20055.0438\n",
      "Epoch 62/250\n",
      "1281/1281 [==============================] - 0s 44us/step - loss: 21449.9943\n",
      "Epoch 63/250\n",
      "1281/1281 [==============================] - 0s 42us/step - loss: 20802.5676\n",
      "Epoch 64/250\n",
      "1281/1281 [==============================] - 0s 56us/step - loss: 21281.1481\n",
      "Epoch 65/250\n",
      "1281/1281 [==============================] - 0s 123us/step - loss: 20385.9914\n",
      "Epoch 66/250\n",
      "1281/1281 [==============================] - 0s 62us/step - loss: 21370.8437\n",
      "Epoch 67/250\n",
      "1281/1281 [==============================] - 0s 43us/step - loss: 20467.0365\n",
      "Epoch 68/250\n",
      "1281/1281 [==============================] - 0s 45us/step - loss: 21248.7519\n",
      "Epoch 69/250\n",
      "1281/1281 [==============================] - 0s 45us/step - loss: 19998.7056\n",
      "Epoch 70/250\n",
      "1281/1281 [==============================] - 0s 49us/step - loss: 20474.1807\n",
      "Epoch 71/250\n",
      "1281/1281 [==============================] - 0s 51us/step - loss: 20629.3470\n",
      "Epoch 72/250\n",
      "1281/1281 [==============================] - 0s 42us/step - loss: 20673.0904\n",
      "Epoch 73/250\n",
      "1281/1281 [==============================] - 0s 56us/step - loss: 19898.3863\n",
      "Epoch 74/250\n",
      "1281/1281 [==============================] - 0s 48us/step - loss: 19703.7445\n",
      "Epoch 75/250\n",
      "1281/1281 [==============================] - 0s 38us/step - loss: 20466.9500\n",
      "Epoch 76/250\n",
      "1281/1281 [==============================] - 0s 35us/step - loss: 19550.7673\n",
      "Epoch 77/250\n",
      "1281/1281 [==============================] - 0s 32us/step - loss: 19974.9172\n",
      "Epoch 78/250\n",
      "1281/1281 [==============================] - 0s 36us/step - loss: 20384.3963\n",
      "Epoch 79/250\n",
      "1281/1281 [==============================] - 0s 35us/step - loss: 19697.9768\n",
      "Epoch 80/250\n",
      "1281/1281 [==============================] - 0s 36us/step - loss: 20146.1840\n",
      "Epoch 81/250\n",
      "1281/1281 [==============================] - 0s 37us/step - loss: 20062.2710\n",
      "Epoch 82/250\n",
      "1281/1281 [==============================] - 0s 42us/step - loss: 18836.0559\n",
      "Epoch 83/250\n",
      "1281/1281 [==============================] - 0s 32us/step - loss: 19773.0023\n",
      "Epoch 84/250\n",
      "1281/1281 [==============================] - 0s 31us/step - loss: 19908.2736\n",
      "Epoch 85/250\n",
      "1281/1281 [==============================] - 0s 31us/step - loss: 20356.4268\n",
      "Epoch 86/250\n",
      "1281/1281 [==============================] - 0s 32us/step - loss: 20373.1656\n",
      "Epoch 87/250\n",
      "1281/1281 [==============================] - 0s 31us/step - loss: 18727.4212\n",
      "Epoch 88/250\n",
      "1281/1281 [==============================] - 0s 32us/step - loss: 20078.0964\n",
      "Epoch 89/250\n",
      "1281/1281 [==============================] - 0s 31us/step - loss: 20889.2597\n",
      "Epoch 90/250\n",
      "1281/1281 [==============================] - 0s 30us/step - loss: 19526.8873\n",
      "Epoch 91/250\n",
      "1281/1281 [==============================] - 0s 31us/step - loss: 19774.4117\n",
      "Epoch 92/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1281/1281 [==============================] - 0s 30us/step - loss: 19340.0539\n",
      "Epoch 93/250\n",
      "1281/1281 [==============================] - 0s 31us/step - loss: 19649.6727\n",
      "Epoch 94/250\n",
      "1281/1281 [==============================] - 0s 33us/step - loss: 19383.9873\n",
      "Epoch 95/250\n",
      "1281/1281 [==============================] - 0s 32us/step - loss: 20030.3908\n",
      "Epoch 96/250\n",
      "1281/1281 [==============================] - 0s 33us/step - loss: 19274.4172\n",
      "Epoch 97/250\n",
      "1281/1281 [==============================] - 0s 32us/step - loss: 19577.0429\n",
      "Epoch 98/250\n",
      "1281/1281 [==============================] - 0s 32us/step - loss: 18702.4709\n",
      "Epoch 99/250\n",
      "1281/1281 [==============================] - 0s 31us/step - loss: 20280.1399\n",
      "Epoch 100/250\n",
      "1281/1281 [==============================] - 0s 37us/step - loss: 19190.6920\n",
      "Epoch 101/250\n",
      "1281/1281 [==============================] - 0s 36us/step - loss: 20491.8865\n",
      "Epoch 102/250\n",
      "1281/1281 [==============================] - 0s 34us/step - loss: 19657.7556\n",
      "Epoch 103/250\n",
      "1281/1281 [==============================] - 0s 43us/step - loss: 19450.1089\n",
      "Epoch 104/250\n",
      "1281/1281 [==============================] - 0s 43us/step - loss: 20413.1800\n",
      "Epoch 105/250\n",
      "1281/1281 [==============================] - 0s 52us/step - loss: 19017.3717\n",
      "Epoch 106/250\n",
      "1281/1281 [==============================] - 0s 33us/step - loss: 18563.5169\n",
      "Epoch 107/250\n",
      "1281/1281 [==============================] - 0s 38us/step - loss: 19414.1400\n",
      "Epoch 108/250\n",
      "1281/1281 [==============================] - 0s 42us/step - loss: 19022.6035\n",
      "Epoch 109/250\n",
      "1281/1281 [==============================] - 0s 36us/step - loss: 19546.5079\n",
      "Epoch 110/250\n",
      "1281/1281 [==============================] - 0s 65us/step - loss: 18877.1876\n",
      "Epoch 111/250\n",
      "1281/1281 [==============================] - 0s 50us/step - loss: 18502.4110\n",
      "Epoch 112/250\n",
      "1281/1281 [==============================] - 0s 36us/step - loss: 19249.6747\n",
      "Epoch 113/250\n",
      "1281/1281 [==============================] - 0s 33us/step - loss: 18998.5372\n",
      "Epoch 114/250\n",
      "1281/1281 [==============================] - 0s 33us/step - loss: 18822.9415\n",
      "Epoch 115/250\n",
      "1281/1281 [==============================] - 0s 31us/step - loss: 19276.4481\n",
      "Epoch 116/250\n",
      "1281/1281 [==============================] - 0s 33us/step - loss: 18146.4259\n",
      "Epoch 117/250\n",
      "1281/1281 [==============================] - 0s 32us/step - loss: 18696.0462\n",
      "Epoch 118/250\n",
      "1281/1281 [==============================] - 0s 32us/step - loss: 18847.1354\n",
      "Epoch 119/250\n",
      "1281/1281 [==============================] - 0s 31us/step - loss: 19463.6557\n",
      "Epoch 120/250\n",
      "1281/1281 [==============================] - 0s 31us/step - loss: 18889.1516\n",
      "Epoch 121/250\n",
      "1281/1281 [==============================] - 0s 32us/step - loss: 18312.5559\n",
      "Epoch 122/250\n",
      "1281/1281 [==============================] - 0s 32us/step - loss: 19020.0057\n",
      "Epoch 123/250\n",
      "1281/1281 [==============================] - 0s 37us/step - loss: 19000.8528\n",
      "Epoch 124/250\n",
      "1281/1281 [==============================] - 0s 36us/step - loss: 18076.6607\n",
      "Epoch 125/250\n",
      "1281/1281 [==============================] - 0s 33us/step - loss: 18812.6776\n",
      "Epoch 126/250\n",
      "1281/1281 [==============================] - 0s 35us/step - loss: 18098.0878\n",
      "Epoch 127/250\n",
      "1281/1281 [==============================] - 0s 34us/step - loss: 19759.3698\n",
      "Epoch 128/250\n",
      "1281/1281 [==============================] - 0s 46us/step - loss: 19104.3204\n",
      "Epoch 129/250\n",
      "1281/1281 [==============================] - 0s 35us/step - loss: 18240.8168\n",
      "Epoch 130/250\n",
      "1281/1281 [==============================] - 0s 33us/step - loss: 18767.5294\n",
      "Epoch 131/250\n",
      "1281/1281 [==============================] - 0s 32us/step - loss: 18523.5863\n",
      "Epoch 132/250\n",
      "1281/1281 [==============================] - 0s 33us/step - loss: 18899.8921\n",
      "Epoch 133/250\n",
      "1281/1281 [==============================] - 0s 32us/step - loss: 19134.2953\n",
      "Epoch 134/250\n",
      "1281/1281 [==============================] - 0s 34us/step - loss: 18624.9332\n",
      "Epoch 135/250\n",
      "1281/1281 [==============================] - 0s 40us/step - loss: 19042.6382\n",
      "Epoch 136/250\n",
      "1281/1281 [==============================] - 0s 39us/step - loss: 18041.1972\n",
      "Epoch 137/250\n",
      "1281/1281 [==============================] - 0s 40us/step - loss: 19952.2376\n",
      "Epoch 138/250\n",
      "1281/1281 [==============================] - 0s 39us/step - loss: 19624.6776\n",
      "Epoch 139/250\n",
      "1281/1281 [==============================] - 0s 50us/step - loss: 18457.2640\n",
      "Epoch 140/250\n",
      "1281/1281 [==============================] - 0s 39us/step - loss: 18563.1754\n",
      "Epoch 141/250\n",
      "1281/1281 [==============================] - 0s 33us/step - loss: 18750.0757\n",
      "Epoch 142/250\n",
      "1281/1281 [==============================] - 0s 32us/step - loss: 18187.3070\n",
      "Epoch 143/250\n",
      "1281/1281 [==============================] - 0s 31us/step - loss: 18099.6969\n",
      "Epoch 144/250\n",
      "1281/1281 [==============================] - 0s 41us/step - loss: 18870.5931\n",
      "Epoch 145/250\n",
      "1281/1281 [==============================] - 0s 35us/step - loss: 18842.7192\n",
      "Epoch 146/250\n",
      "1281/1281 [==============================] - 0s 32us/step - loss: 18825.1505\n",
      "Epoch 147/250\n",
      "1281/1281 [==============================] - 0s 33us/step - loss: 19600.2868\n",
      "Epoch 148/250\n",
      "1281/1281 [==============================] - 0s 32us/step - loss: 18993.1244\n",
      "Epoch 149/250\n",
      "1281/1281 [==============================] - 0s 33us/step - loss: 18324.8882\n",
      "Epoch 150/250\n",
      "1281/1281 [==============================] - 0s 32us/step - loss: 18577.1090\n",
      "Epoch 151/250\n",
      "1281/1281 [==============================] - 0s 31us/step - loss: 19097.6992\n",
      "Epoch 152/250\n",
      "1281/1281 [==============================] - 0s 33us/step - loss: 18524.0538\n",
      "Epoch 153/250\n",
      "1281/1281 [==============================] - 0s 32us/step - loss: 18019.6915\n",
      "Epoch 154/250\n",
      "1281/1281 [==============================] - 0s 36us/step - loss: 18037.3410\n",
      "Epoch 155/250\n",
      "1281/1281 [==============================] - 0s 33us/step - loss: 18452.5443\n",
      "Epoch 156/250\n",
      "1281/1281 [==============================] - 0s 35us/step - loss: 18210.0296\n",
      "Epoch 157/250\n",
      "1281/1281 [==============================] - 0s 36us/step - loss: 18939.0521\n",
      "Epoch 158/250\n",
      "1281/1281 [==============================] - 0s 46us/step - loss: 17859.0118\n",
      "Epoch 159/250\n",
      "1281/1281 [==============================] - 0s 35us/step - loss: 18374.7691\n",
      "Epoch 160/250\n",
      "1281/1281 [==============================] - 0s 39us/step - loss: 17991.5054\n",
      "Epoch 161/250\n",
      "1281/1281 [==============================] - 0s 47us/step - loss: 18155.9993\n",
      "Epoch 162/250\n",
      "1281/1281 [==============================] - 0s 33us/step - loss: 18408.9361\n",
      "Epoch 163/250\n",
      "1281/1281 [==============================] - 0s 32us/step - loss: 18804.9170\n",
      "Epoch 164/250\n",
      "1281/1281 [==============================] - 0s 34us/step - loss: 18176.3941\n",
      "Epoch 165/250\n",
      "1281/1281 [==============================] - 0s 38us/step - loss: 18790.0857\n",
      "Epoch 166/250\n",
      "1281/1281 [==============================] - 0s 33us/step - loss: 18991.4902\n",
      "Epoch 167/250\n",
      "1281/1281 [==============================] - 0s 34us/step - loss: 17479.1991\n",
      "Epoch 168/250\n",
      "1281/1281 [==============================] - 0s 71us/step - loss: 17838.5717\n",
      "Epoch 169/250\n",
      "1281/1281 [==============================] - 0s 79us/step - loss: 17880.0373\n",
      "Epoch 170/250\n",
      "1281/1281 [==============================] - 0s 100us/step - loss: 17861.2958\n",
      "Epoch 171/250\n",
      "1281/1281 [==============================] - 0s 84us/step - loss: 18817.9675\n",
      "Epoch 172/250\n",
      "1281/1281 [==============================] - 0s 56us/step - loss: 19185.2802\n",
      "Epoch 173/250\n",
      "1281/1281 [==============================] - 0s 61us/step - loss: 18691.5418\n",
      "Epoch 174/250\n",
      "1281/1281 [==============================] - 0s 48us/step - loss: 18183.7325\n",
      "Epoch 175/250\n",
      "1281/1281 [==============================] - 0s 47us/step - loss: 19103.0636\n",
      "Epoch 176/250\n",
      "1281/1281 [==============================] - 0s 35us/step - loss: 18616.6461\n",
      "Epoch 177/250\n",
      "1281/1281 [==============================] - 0s 40us/step - loss: 18134.2960\n",
      "Epoch 178/250\n",
      "1281/1281 [==============================] - 0s 34us/step - loss: 18828.8388\n",
      "Epoch 179/250\n",
      "1281/1281 [==============================] - 0s 50us/step - loss: 18004.8018\n",
      "Epoch 180/250\n",
      "1281/1281 [==============================] - 0s 39us/step - loss: 18450.7118\n",
      "Epoch 181/250\n",
      "1281/1281 [==============================] - 0s 36us/step - loss: 18059.9207\n",
      "Epoch 182/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1281/1281 [==============================] - 0s 48us/step - loss: 17552.5402\n",
      "Epoch 183/250\n",
      "1281/1281 [==============================] - 0s 106us/step - loss: 18028.9280\n",
      "Epoch 184/250\n",
      "1281/1281 [==============================] - 0s 85us/step - loss: 17669.2352\n",
      "Epoch 185/250\n",
      "1281/1281 [==============================] - 0s 67us/step - loss: 19493.2120\n",
      "Epoch 186/250\n",
      "1281/1281 [==============================] - 0s 58us/step - loss: 18351.4604\n",
      "Epoch 187/250\n",
      "1281/1281 [==============================] - 0s 40us/step - loss: 18646.0878\n",
      "Epoch 188/250\n",
      "1281/1281 [==============================] - 0s 41us/step - loss: 18740.6167\n",
      "Epoch 189/250\n",
      "1281/1281 [==============================] - 0s 55us/step - loss: 17984.1045\n",
      "Epoch 190/250\n",
      "1281/1281 [==============================] - 0s 47us/step - loss: 18363.4666\n",
      "Epoch 191/250\n",
      "1281/1281 [==============================] - 0s 36us/step - loss: 17819.8527\n",
      "Epoch 192/250\n",
      "1281/1281 [==============================] - 0s 33us/step - loss: 18042.7760\n",
      "Epoch 193/250\n",
      "1281/1281 [==============================] - 0s 41us/step - loss: 17711.1309\n",
      "Epoch 194/250\n",
      "1281/1281 [==============================] - 0s 32us/step - loss: 17011.0984\n",
      "Epoch 195/250\n",
      "1281/1281 [==============================] - 0s 32us/step - loss: 19032.3495\n",
      "Epoch 196/250\n",
      "1281/1281 [==============================] - 0s 33us/step - loss: 18356.0348\n",
      "Epoch 197/250\n",
      "1281/1281 [==============================] - 0s 34us/step - loss: 18600.2578\n",
      "Epoch 198/250\n",
      "1281/1281 [==============================] - 0s 33us/step - loss: 18624.8033\n",
      "Epoch 199/250\n",
      "1281/1281 [==============================] - 0s 33us/step - loss: 18316.4838\n",
      "Epoch 200/250\n",
      "1281/1281 [==============================] - 0s 50us/step - loss: 18343.3675\n",
      "Epoch 201/250\n",
      "1281/1281 [==============================] - 0s 95us/step - loss: 17835.9195\n",
      "Epoch 202/250\n",
      "1281/1281 [==============================] - 0s 86us/step - loss: 18068.1425\n",
      "Epoch 203/250\n",
      "1281/1281 [==============================] - 0s 75us/step - loss: 17930.9791\n",
      "Epoch 204/250\n",
      "1281/1281 [==============================] - 0s 59us/step - loss: 18510.9060\n",
      "Epoch 205/250\n",
      "1281/1281 [==============================] - 0s 51us/step - loss: 17410.1309\n",
      "Epoch 206/250\n",
      "1281/1281 [==============================] - 0s 57us/step - loss: 17967.5244\n",
      "Epoch 207/250\n",
      "1281/1281 [==============================] - 0s 54us/step - loss: 18655.8308\n",
      "Epoch 208/250\n",
      "1281/1281 [==============================] - 0s 46us/step - loss: 17822.4695\n",
      "Epoch 209/250\n",
      "1281/1281 [==============================] - 0s 43us/step - loss: 18493.2891\n",
      "Epoch 210/250\n",
      "1281/1281 [==============================] - 0s 41us/step - loss: 17449.8087\n",
      "Epoch 211/250\n",
      "1281/1281 [==============================] - 0s 42us/step - loss: 17952.5100\n",
      "Epoch 212/250\n",
      "1281/1281 [==============================] - 0s 65us/step - loss: 18417.9711\n",
      "Epoch 213/250\n",
      "1281/1281 [==============================] - 0s 57us/step - loss: 18299.5739\n",
      "Epoch 214/250\n",
      "1281/1281 [==============================] - 0s 56us/step - loss: 17819.0552\n",
      "Epoch 215/250\n",
      "1281/1281 [==============================] - 0s 64us/step - loss: 18096.6107\n",
      "Epoch 216/250\n",
      "1281/1281 [==============================] - 0s 58us/step - loss: 19278.9616\n",
      "Epoch 217/250\n",
      "1281/1281 [==============================] - 0s 48us/step - loss: 17823.5013\n",
      "Epoch 218/250\n",
      "1281/1281 [==============================] - 0s 45us/step - loss: 18066.6323\n",
      "Epoch 219/250\n",
      "1281/1281 [==============================] - 0s 42us/step - loss: 17997.6790\n",
      "Epoch 220/250\n",
      "1281/1281 [==============================] - 0s 45us/step - loss: 18673.1892\n",
      "Epoch 221/250\n",
      "1281/1281 [==============================] - 0s 77us/step - loss: 17528.4077\n",
      "Epoch 222/250\n",
      "1281/1281 [==============================] - 0s 81us/step - loss: 18275.5815\n",
      "Epoch 223/250\n",
      "1281/1281 [==============================] - 0s 71us/step - loss: 17856.2643\n",
      "Epoch 224/250\n",
      "1281/1281 [==============================] - 0s 78us/step - loss: 17041.8070\n",
      "Epoch 225/250\n",
      "1281/1281 [==============================] - 0s 64us/step - loss: 18159.5176\n",
      "Epoch 226/250\n",
      "1281/1281 [==============================] - 0s 65us/step - loss: 18234.6026\n",
      "Epoch 227/250\n",
      "1281/1281 [==============================] - 0s 63us/step - loss: 17578.2382\n",
      "Epoch 228/250\n",
      "1281/1281 [==============================] - 0s 56us/step - loss: 18793.6223\n",
      "Epoch 229/250\n",
      "1281/1281 [==============================] - 0s 60us/step - loss: 17065.8475\n",
      "Epoch 230/250\n",
      "1281/1281 [==============================] - 0s 60us/step - loss: 19563.7411\n",
      "Epoch 231/250\n",
      "1281/1281 [==============================] - 0s 57us/step - loss: 17732.8537\n",
      "Epoch 232/250\n",
      "1281/1281 [==============================] - 0s 56us/step - loss: 18250.0672\n",
      "Epoch 233/250\n",
      "1281/1281 [==============================] - ETA: 0s - loss: 22539.400 - 0s 37us/step - loss: 18136.5724\n",
      "Epoch 234/250\n",
      "1281/1281 [==============================] - 0s 63us/step - loss: 17238.1999\n",
      "Epoch 235/250\n",
      "1281/1281 [==============================] - 0s 77us/step - loss: 18278.9016\n",
      "Epoch 236/250\n",
      "1281/1281 [==============================] - 0s 47us/step - loss: 18031.8492\n",
      "Epoch 237/250\n",
      "1281/1281 [==============================] - 0s 51us/step - loss: 17658.9328\n",
      "Epoch 238/250\n",
      "1281/1281 [==============================] - 0s 50us/step - loss: 18332.0450\n",
      "Epoch 239/250\n",
      "1281/1281 [==============================] - 0s 54us/step - loss: 17613.9236\n",
      "Epoch 240/250\n",
      "1281/1281 [==============================] - 0s 66us/step - loss: 17985.3380\n",
      "Epoch 241/250\n",
      "1281/1281 [==============================] - 0s 56us/step - loss: 18420.4406\n",
      "Epoch 242/250\n",
      "1281/1281 [==============================] - 0s 61us/step - loss: 17825.1306\n",
      "Epoch 243/250\n",
      "1281/1281 [==============================] - 0s 60us/step - loss: 17361.2341\n",
      "Epoch 244/250\n",
      "1281/1281 [==============================] - 0s 57us/step - loss: 16871.0259\n",
      "Epoch 245/250\n",
      "1281/1281 [==============================] - 0s 51us/step - loss: 17188.1061\n",
      "Epoch 246/250\n",
      "1281/1281 [==============================] - 0s 52us/step - loss: 17974.1420\n",
      "Epoch 247/250\n",
      "1281/1281 [==============================] - 0s 47us/step - loss: 17878.6743\n",
      "Epoch 248/250\n",
      "1281/1281 [==============================] - 0s 63us/step - loss: 17935.9421\n",
      "Epoch 249/250\n",
      "1281/1281 [==============================] - 0s 40us/step - loss: 17575.9105\n",
      "Epoch 250/250\n",
      "1281/1281 [==============================] - 0s 44us/step - loss: 18257.7520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1163fd6d8>"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=250, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1281/1281 [==============================] - 0s 51us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13022.089966773243"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321/321 [==============================] - 0s 46us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13692.947099822333"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-64.0, 1344.0, -391.2797401428223, 173.53744583129884)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAD5CAYAAADGMZVsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19f1123c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.predict(X_train).reshape(-1)- y_train.values, color='blue', label='train')\n",
    "plt.plot(model.predict(X_test).reshape(-1)-y_test.values, color='red', label='test')\n",
    "plt.legend()\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Still high residuals. Model did not generalize to the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Classification with Log Res and MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1163fd710>"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAD5CAYAAADodLT+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCG8AMND/AxDqjyjVolPkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17bbb2dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cy = (y>=208).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, cy, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log = LogisticRegressionCV(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight='balanced', cv=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "           refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6370023419203747"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5825545171339563"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    744\n",
       "1    537\n",
       "Name: success, dtype: int64"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5807962529274004"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "744/(537+744)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model just about does the same as random guessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.2 Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8, input_shape = (X_train.shape[1],)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "es = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1281 samples, validate on 321 samples\n",
      "Epoch 1/250\n",
      "1281/1281 [==============================] - 2s 2ms/step - loss: 4.3893 - acc: 0.3903 - val_loss: 4.8476 - val_acc: 0.5670\n",
      "Epoch 2/250\n",
      "1281/1281 [==============================] - 0s 47us/step - loss: 4.0462 - acc: 0.4590 - val_loss: 1.2368 - val_acc: 0.5670\n",
      "Epoch 3/250\n",
      "1281/1281 [==============================] - 0s 60us/step - loss: 3.8911 - acc: 0.4582 - val_loss: 0.8018 - val_acc: 0.5452\n",
      "Epoch 4/250\n",
      "1281/1281 [==============================] - 0s 57us/step - loss: 3.9419 - acc: 0.4645 - val_loss: 0.8174 - val_acc: 0.5607\n",
      "Epoch 5/250\n",
      "1281/1281 [==============================] - 0s 62us/step - loss: 3.5177 - acc: 0.4738 - val_loss: 1.0529 - val_acc: 0.5670\n",
      "Epoch 6/250\n",
      "1281/1281 [==============================] - 0s 59us/step - loss: 3.2788 - acc: 0.4988 - val_loss: 1.0089 - val_acc: 0.5670\n",
      "Epoch 7/250\n",
      "1281/1281 [==============================] - 0s 60us/step - loss: 3.1593 - acc: 0.5113 - val_loss: 0.8919 - val_acc: 0.5670\n",
      "Epoch 8/250\n",
      "1281/1281 [==============================] - 0s 44us/step - loss: 2.6998 - acc: 0.5379 - val_loss: 0.7750 - val_acc: 0.5483\n",
      "Epoch 9/250\n",
      "1281/1281 [==============================] - 0s 65us/step - loss: 2.9805 - acc: 0.5043 - val_loss: 0.8895 - val_acc: 0.5670\n",
      "Epoch 10/250\n",
      "1281/1281 [==============================] - 0s 63us/step - loss: 2.8256 - acc: 0.5176 - val_loss: 0.8548 - val_acc: 0.5670\n",
      "Epoch 11/250\n",
      "1281/1281 [==============================] - 0s 66us/step - loss: 2.8870 - acc: 0.5277 - val_loss: 0.8431 - val_acc: 0.5670\n",
      "Epoch 12/250\n",
      "1281/1281 [==============================] - 0s 62us/step - loss: 2.6030 - acc: 0.5262 - val_loss: 0.8269 - val_acc: 0.5670\n",
      "Epoch 13/250\n",
      "1281/1281 [==============================] - 0s 61us/step - loss: 2.1346 - acc: 0.5519 - val_loss: 0.8115 - val_acc: 0.5670\n",
      "Epoch 14/250\n",
      "1281/1281 [==============================] - 0s 56us/step - loss: 2.6014 - acc: 0.5160 - val_loss: 0.7749 - val_acc: 0.4579\n",
      "Epoch 15/250\n",
      "1281/1281 [==============================] - 0s 57us/step - loss: 2.8018 - acc: 0.4809 - val_loss: 0.7469 - val_acc: 0.4673\n",
      "Epoch 16/250\n",
      "1281/1281 [==============================] - 0s 56us/step - loss: 2.0808 - acc: 0.5496 - val_loss: 0.7186 - val_acc: 0.5514\n",
      "Epoch 17/250\n",
      "1281/1281 [==============================] - 0s 55us/step - loss: 1.8732 - acc: 0.5410 - val_loss: 0.7241 - val_acc: 0.5576\n",
      "Epoch 18/250\n",
      "1281/1281 [==============================] - 0s 61us/step - loss: 1.8380 - acc: 0.5480 - val_loss: 0.7317 - val_acc: 0.5670\n",
      "Epoch 19/250\n",
      "1281/1281 [==============================] - 0s 65us/step - loss: 1.6313 - acc: 0.5262 - val_loss: 0.7374 - val_acc: 0.5639\n",
      "Epoch 20/250\n",
      "1281/1281 [==============================] - 0s 59us/step - loss: 1.8596 - acc: 0.5410 - val_loss: 0.7087 - val_acc: 0.5514\n",
      "Epoch 21/250\n",
      "1281/1281 [==============================] - 0s 62us/step - loss: 2.5556 - acc: 0.4988 - val_loss: 0.7077 - val_acc: 0.5421\n",
      "Epoch 22/250\n",
      "1281/1281 [==============================] - 0s 61us/step - loss: 2.3535 - acc: 0.5035 - val_loss: 0.7043 - val_acc: 0.5545\n",
      "Epoch 23/250\n",
      "1281/1281 [==============================] - 0s 68us/step - loss: 2.1831 - acc: 0.5074 - val_loss: 0.7041 - val_acc: 0.5639\n",
      "Epoch 24/250\n",
      "1281/1281 [==============================] - 0s 64us/step - loss: 2.0714 - acc: 0.5308 - val_loss: 0.7038 - val_acc: 0.5639\n",
      "Epoch 25/250\n",
      "1281/1281 [==============================] - 0s 62us/step - loss: 1.8445 - acc: 0.5113 - val_loss: 0.6999 - val_acc: 0.5576\n",
      "Epoch 26/250\n",
      "1281/1281 [==============================] - 0s 63us/step - loss: 1.6059 - acc: 0.5035 - val_loss: 0.7022 - val_acc: 0.5701\n",
      "Epoch 27/250\n",
      "1281/1281 [==============================] - 0s 64us/step - loss: 1.6496 - acc: 0.5441 - val_loss: 0.8248 - val_acc: 0.5670\n",
      "Epoch 28/250\n",
      "1281/1281 [==============================] - 0s 61us/step - loss: 2.2491 - acc: 0.5511 - val_loss: 0.7716 - val_acc: 0.5670\n",
      "Epoch 29/250\n",
      "1281/1281 [==============================] - 0s 57us/step - loss: 1.7014 - acc: 0.5425 - val_loss: 0.7661 - val_acc: 0.5670\n",
      "Epoch 30/250\n",
      "1281/1281 [==============================] - 0s 69us/step - loss: 1.4634 - acc: 0.5628 - val_loss: 0.7436 - val_acc: 0.5670\n",
      "Epoch 31/250\n",
      "1281/1281 [==============================] - 0s 58us/step - loss: 1.2420 - acc: 0.5558 - val_loss: 0.7259 - val_acc: 0.5670\n",
      "Epoch 32/250\n",
      "1281/1281 [==============================] - 0s 58us/step - loss: 1.1070 - acc: 0.5667 - val_loss: 0.7150 - val_acc: 0.5670\n",
      "Epoch 33/250\n",
      "1281/1281 [==============================] - 0s 55us/step - loss: 1.1893 - acc: 0.5527 - val_loss: 0.7085 - val_acc: 0.5639\n",
      "Epoch 34/250\n",
      "1281/1281 [==============================] - 0s 60us/step - loss: 1.0423 - acc: 0.5574 - val_loss: 0.7012 - val_acc: 0.5639\n",
      "Epoch 35/250\n",
      "1281/1281 [==============================] - 0s 64us/step - loss: 1.0362 - acc: 0.5464 - val_loss: 0.6977 - val_acc: 0.5639\n",
      "Epoch 36/250\n",
      "1281/1281 [==============================] - 0s 55us/step - loss: 0.9730 - acc: 0.5316 - val_loss: 0.6994 - val_acc: 0.5639\n",
      "Epoch 37/250\n",
      "1281/1281 [==============================] - 0s 58us/step - loss: 0.9491 - acc: 0.5683 - val_loss: 0.6982 - val_acc: 0.5639\n",
      "Epoch 38/250\n",
      "1281/1281 [==============================] - 0s 85us/step - loss: 0.9609 - acc: 0.5332 - val_loss: 0.6957 - val_acc: 0.5639\n",
      "Epoch 39/250\n",
      "1281/1281 [==============================] - 0s 85us/step - loss: 1.0033 - acc: 0.5215 - val_loss: 0.6952 - val_acc: 0.5639\n",
      "Epoch 40/250\n",
      "1281/1281 [==============================] - 0s 55us/step - loss: 0.9017 - acc: 0.5574 - val_loss: 0.6946 - val_acc: 0.5639\n",
      "Epoch 41/250\n",
      "1281/1281 [==============================] - 0s 52us/step - loss: 0.9101 - acc: 0.5535 - val_loss: 0.6944 - val_acc: 0.5639\n",
      "Epoch 42/250\n",
      "1281/1281 [==============================] - 0s 62us/step - loss: 0.9106 - acc: 0.5496 - val_loss: 0.7093 - val_acc: 0.5670\n",
      "Epoch 43/250\n",
      "1281/1281 [==============================] - 0s 57us/step - loss: 1.0140 - acc: 0.5558 - val_loss: 0.7043 - val_acc: 0.5670\n",
      "Epoch 44/250\n",
      "1281/1281 [==============================] - 0s 57us/step - loss: 0.9596 - acc: 0.5628 - val_loss: 0.6967 - val_acc: 0.5639\n",
      "Epoch 45/250\n",
      "1281/1281 [==============================] - 0s 58us/step - loss: 0.9165 - acc: 0.5543 - val_loss: 0.6924 - val_acc: 0.5452\n",
      "Epoch 46/250\n",
      "1281/1281 [==============================] - 0s 76us/step - loss: 1.9557 - acc: 0.5035 - val_loss: 0.7203 - val_acc: 0.4642\n",
      "Epoch 47/250\n",
      "1281/1281 [==============================] - 0s 83us/step - loss: 2.2308 - acc: 0.5051 - val_loss: 0.7043 - val_acc: 0.4953\n",
      "Epoch 48/250\n",
      "1281/1281 [==============================] - 0s 76us/step - loss: 1.6562 - acc: 0.5176 - val_loss: 0.6894 - val_acc: 0.5639\n",
      "Epoch 49/250\n",
      "1281/1281 [==============================] - 0s 76us/step - loss: 1.3945 - acc: 0.5137 - val_loss: 0.6863 - val_acc: 0.5701\n",
      "Epoch 50/250\n",
      "1281/1281 [==============================] - 0s 72us/step - loss: 1.4815 - acc: 0.5207 - val_loss: 0.7892 - val_acc: 0.5670\n",
      "Epoch 51/250\n",
      "1281/1281 [==============================] - 0s 71us/step - loss: 1.5552 - acc: 0.5027 - val_loss: 0.7074 - val_acc: 0.4798\n",
      "Epoch 52/250\n",
      "1281/1281 [==============================] - 0s 66us/step - loss: 1.8272 - acc: 0.5285 - val_loss: 0.7089 - val_acc: 0.4860\n",
      "Epoch 53/250\n",
      "1281/1281 [==============================] - 0s 65us/step - loss: 1.9979 - acc: 0.5043 - val_loss: 0.6962 - val_acc: 0.5140\n",
      "Epoch 54/250\n",
      "1281/1281 [==============================] - 0s 68us/step - loss: 1.6336 - acc: 0.5246 - val_loss: 0.6879 - val_acc: 0.5545\n",
      "Epoch 55/250\n",
      "1281/1281 [==============================] - 0s 55us/step - loss: 1.5453 - acc: 0.5293 - val_loss: 0.6866 - val_acc: 0.5701\n",
      "Epoch 56/250\n",
      "1281/1281 [==============================] - 0s 58us/step - loss: 1.3491 - acc: 0.5519 - val_loss: 0.6857 - val_acc: 0.5607\n",
      "Epoch 57/250\n",
      "1281/1281 [==============================] - ETA: 0s - loss: 1.1393 - acc: 0.562 - 0s 81us/step - loss: 1.2197 - acc: 0.5496 - val_loss: 0.6857 - val_acc: 0.5639\n",
      "Epoch 58/250\n",
      "1281/1281 [==============================] - 0s 57us/step - loss: 1.1256 - acc: 0.5589 - val_loss: 0.6870 - val_acc: 0.5670\n",
      "Epoch 59/250\n",
      "1281/1281 [==============================] - 0s 67us/step - loss: 1.1605 - acc: 0.5293 - val_loss: 0.6873 - val_acc: 0.5639\n",
      "Epoch 60/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1281/1281 [==============================] - 0s 77us/step - loss: 1.1429 - acc: 0.5215 - val_loss: 0.6870 - val_acc: 0.5607\n",
      "Epoch 61/250\n",
      "1281/1281 [==============================] - 0s 70us/step - loss: 1.1240 - acc: 0.5191 - val_loss: 0.6874 - val_acc: 0.5639\n",
      "Epoch 62/250\n",
      "1281/1281 [==============================] - 0s 69us/step - loss: 1.0181 - acc: 0.5363 - val_loss: 0.6862 - val_acc: 0.5576\n",
      "Epoch 63/250\n",
      "1281/1281 [==============================] - 0s 68us/step - loss: 1.0458 - acc: 0.5137 - val_loss: 0.6865 - val_acc: 0.5639\n",
      "Epoch 64/250\n",
      "1281/1281 [==============================] - 0s 76us/step - loss: 0.8542 - acc: 0.5402 - val_loss: 0.6905 - val_acc: 0.5670\n",
      "Epoch 65/250\n",
      "1281/1281 [==============================] - 0s 60us/step - loss: 0.8279 - acc: 0.5652 - val_loss: 0.6907 - val_acc: 0.5670\n",
      "Epoch 66/250\n",
      "1281/1281 [==============================] - 0s 62us/step - loss: 0.8082 - acc: 0.5582 - val_loss: 0.6919 - val_acc: 0.5670\n",
      "Epoch 67/250\n",
      "1281/1281 [==============================] - 0s 54us/step - loss: 0.7648 - acc: 0.5785 - val_loss: 0.6927 - val_acc: 0.5670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x198109e48>"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=250, batch_size=64, class_weight=y_train, validation_data=(X_test, y_test), callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1281/1281 [==============================] - 0s 49us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6893631466937009, 0.5807962529274004]"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321/321 [==============================] - 0s 56us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6926563574331943, 0.5669781931464174]"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[182   0]\n",
      " [139   0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      1.00      0.72       182\n",
      "          1       0.00      0.00      0.00       139\n",
      "\n",
      "avg / total       0.32      0.57      0.41       321\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piocalderon/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, model.predict_classes(X_test).reshape(-1)))\n",
    "print(classification_report(y_test, model.predict_classes(X_test).reshape(-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with LSTM models\n",
    "\n",
    "## 1. embedding vector -> LSTM -> success\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vw = pd.read_csv('../processed/processed_volkswagenpolska.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vw = vw[['tokens', 'Trendy',\n",
    "       'Kind', 'Polite', 'Warm', 'Diligent', 'Blue_Collar', 'White_Collar',\n",
    "       'Protective', 'Serious', 'Funny', 'Pleasant', 'Beautiful', 'Alive',\n",
    "       'Above', 'Descriptive', 'Cheap', 'Expensive', 'Big', 'Small', 'Modern',\n",
    "       'Traditional', 'Appealing', 'Sustainable', 'Practical', 'Active',\n",
    "       'Easy', 'Trustworthy', 'Natural', 'Arts', 'Career', 'Family', 'Female',\n",
    "       'Male', 'Math', 'Science', 'Open', 'Cool', 'Likeable', 'Children',\n",
    "       'Community', 'Culture', 'Design', 'Innovative', 'Responsible',\n",
    "       'Extroverted', 'Fascination', 'Friendship', 'Functionality', 'Winner',\n",
    "       'Lifestyle', 'Music', 'New', 'Bargain', 'Power', 'Safety', 'Teaching',\n",
    "       'Technical', 'Valuable', 'Feel Good', 'Support', 'Inspire', 'Happiness',\n",
    "       'Celebrate', 'Meaningful', 'success']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = vw['success']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# retain = (y[pd.qcut(y, 10, labels=range(10)).isin([0])]).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vw = vw.loc[retain,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vw['tokens'] = vw['tokens'].map(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vw = vw[~vw['Trendy'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vw['sequence'] = vw['tokens'].map(lambda words: [get_average_vector([x], emb) for x in words if x in emb.vocab.keys() and x not in ['bezpieczeństwo', 'pistolet']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clip(seq):\n",
    "    x = None\n",
    "    if len(seq) >= 50:\n",
    "        x = seq[:50]\n",
    "        return x\n",
    "    else:\n",
    "        x = seq.copy()\n",
    "        x.extend(np.zeros((50 - len(seq),300), dtype=np.float32))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vw['clipped'] = vw['sequence'].map(clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276.9885229540918"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vw['success'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vw['class'] = (vw['success']>=208).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1127\n",
       "1     877\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vw['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = vw[['clipped', 'Trendy',\n",
    "       'Kind', 'Polite', 'Warm', 'Diligent', 'Blue_Collar', 'White_Collar',\n",
    "       'Protective', 'Serious', 'Funny', 'Pleasant', 'Beautiful', 'Alive',\n",
    "       'Above', 'Descriptive', 'Cheap', 'Expensive', 'Big', 'Small', 'Modern',\n",
    "       'Traditional', 'Appealing', 'Sustainable', 'Practical', 'Active',\n",
    "       'Easy', 'Trustworthy', 'Natural', 'Arts', 'Career', 'Family', 'Female',\n",
    "       'Male', 'Math', 'Science', 'Open', 'Cool', 'Likeable', 'Children',\n",
    "       'Community', 'Culture', 'Design', 'Innovative', 'Responsible',\n",
    "       'Extroverted', 'Fascination', 'Friendship', 'Functionality', 'Winner',\n",
    "       'Lifestyle', 'Music', 'New', 'Bargain', 'Power', 'Safety', 'Teaching',\n",
    "       'Technical', 'Valuable', 'Feel Good', 'Support', 'Inspire', 'Happiness',\n",
    "       'Celebrate', 'Meaningful']]\n",
    "y = vw['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valtest, y_train, y_valtest = train_test_split(X, y, test_size=0.40, random_state=42, stratify = y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_valtest, y_valtest, test_size=0.50, random_state=42, stratify = y_valtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_train = []\n",
    "for i in range(len(X_train)):\n",
    "    wv_train.append(np.array(X_train['clipped'].values[i]))\n",
    "wv_train = np.array(wv_train)\n",
    "\n",
    "wv_val = []\n",
    "for i in range(len(X_val)):\n",
    "    wv_val.append(np.array(X_val['clipped'].values[i]))\n",
    "wv_val = np.array(wv_val)\n",
    "\n",
    "wv_test = []\n",
    "for i in range(len(X_test)):\n",
    "    wv_test.append(np.array(X_test['clipped'].values[i]))\n",
    "wv_test = np.array(wv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(LSTM(16, input_shape=(wv_train.shape[1],wv_train.shape[2],)))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(8, activation='relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "es = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1202 samples, validate on 401 samples\n",
      "Epoch 1/50\n",
      "1202/1202 [==============================] - 5s 4ms/step - loss: 0.6967 - acc: 0.5341 - val_loss: 0.6912 - val_acc: 0.5561\n",
      "Epoch 2/50\n",
      "1202/1202 [==============================] - 1s 1ms/step - loss: 0.6902 - acc: 0.5574 - val_loss: 0.6878 - val_acc: 0.5636\n",
      "Epoch 3/50\n",
      "1202/1202 [==============================] - 1s 1ms/step - loss: 0.6875 - acc: 0.5666 - val_loss: 0.6863 - val_acc: 0.5636\n",
      "Epoch 4/50\n",
      "1202/1202 [==============================] - 1s 1ms/step - loss: 0.6896 - acc: 0.5649 - val_loss: 0.6860 - val_acc: 0.5611\n",
      "Epoch 5/50\n",
      "1202/1202 [==============================] - 1s 1ms/step - loss: 0.6863 - acc: 0.5666 - val_loss: 0.6860 - val_acc: 0.5611\n",
      "Epoch 6/50\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.6828 - acc: 0.5691 - val_loss: 0.6855 - val_acc: 0.5636\n",
      "Epoch 7/50\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.6780 - acc: 0.5641 - val_loss: 0.6847 - val_acc: 0.5636\n",
      "Epoch 8/50\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.6808 - acc: 0.5657 - val_loss: 0.6838 - val_acc: 0.5611\n",
      "Epoch 9/50\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.6788 - acc: 0.5691 - val_loss: 0.6833 - val_acc: 0.5611\n",
      "Epoch 10/50\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.6798 - acc: 0.5657 - val_loss: 0.6817 - val_acc: 0.5611\n",
      "Epoch 11/50\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.6735 - acc: 0.5707 - val_loss: 0.6758 - val_acc: 0.5611\n",
      "Epoch 12/50\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.6643 - acc: 0.5691 - val_loss: 0.6711 - val_acc: 0.5611\n",
      "Epoch 13/50\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.6586 - acc: 0.5666 - val_loss: 0.6715 - val_acc: 0.5611\n",
      "Epoch 14/50\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.6481 - acc: 0.5740 - val_loss: 0.6726 - val_acc: 0.5636\n",
      "Epoch 15/50\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.6231 - acc: 0.5907 - val_loss: 0.6772 - val_acc: 0.5985\n",
      "Epoch 16/50\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.5990 - acc: 0.6448 - val_loss: 0.6753 - val_acc: 0.5960\n",
      "Epoch 17/50\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.5703 - acc: 0.6589 - val_loss: 0.6938 - val_acc: 0.6085\n",
      "Epoch 18/50\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.5390 - acc: 0.6955 - val_loss: 0.6922 - val_acc: 0.6060\n",
      "Epoch 19/50\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.5411 - acc: 0.7205 - val_loss: 0.7087 - val_acc: 0.5810\n",
      "Epoch 20/50\n",
      "1202/1202 [==============================] - 1s 1ms/step - loss: 0.5412 - acc: 0.7055 - val_loss: 0.7340 - val_acc: 0.5910\n",
      "Epoch 21/50\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.5008 - acc: 0.7221 - val_loss: 0.7763 - val_acc: 0.6185\n",
      "Epoch 22/50\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.4740 - acc: 0.7629 - val_loss: 0.8096 - val_acc: 0.5935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1afcdab38>"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(wv_train, y_train, epochs=50, batch_size=64, class_weight=y_train, validation_data=(wv_val, y_val), callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1202/1202 [==============================] - 1s 596us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.41702984831297457, 0.801996671915451]"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(wv_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[452 224]\n",
      " [ 14 512]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.67      0.79       676\n",
      "          1       0.70      0.97      0.81       526\n",
      "\n",
      "avg / total       0.85      0.80      0.80      1202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, model1.predict_classes(wv_train).reshape(-1)))\n",
    "print(classification_report(y_train, model1.predict_classes(wv_train).reshape(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401/401 [==============================] - 0s 554us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8095539288033273, 0.5935162095506292]"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(wv_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[108 117]\n",
      " [ 46 130]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.48      0.57       225\n",
      "          1       0.53      0.74      0.61       176\n",
      "\n",
      "avg / total       0.62      0.59      0.59       401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_val, model1.predict_classes(wv_val).reshape(-1)))\n",
    "print(classification_report(y_val, model1.predict_classes(wv_val).reshape(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401/401 [==============================] - 0s 452us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8316488358148019, 0.571072319945195]"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(wv_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1.save('lstm1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. (embedding vector -> LSTM) + (dimension similarity) -> success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sim_train = X_train.iloc[:,1:]\n",
    "sim_val = X_val.iloc[:,1:]\n",
    "sim_test = X_test.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_input = Input(shape=(wv_train.shape[1], wv_train.shape[2],), dtype='float32', name='main_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm = LSTM(16)(main_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auxiliary_input = Input(shape=(sim_train.shape[1], ), name='aux_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = concatenate([lstm, auxiliary_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop1 = Dropout(0.5)(x)\n",
    "dense1 = Dense(8, activation='relu')(drop1)\n",
    "drop2 = Dropout(0.5)(dense1)\n",
    "main_output = Dense(1, activation='sigmoid', name='main_output')(drop2)\n",
    "es = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Model(inputs=[main_input, auxiliary_input], outputs=[main_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1202 samples, validate on 401 samples\n",
      "Epoch 1/50\n",
      "1202/1202 [==============================] - 4s 4ms/step - loss: 0.6998 - acc: 0.5075 - val_loss: 0.6901 - val_acc: 0.5486\n",
      "Epoch 2/50\n",
      "1202/1202 [==============================] - 1s 1ms/step - loss: 0.6908 - acc: 0.5491 - val_loss: 0.6878 - val_acc: 0.5611\n",
      "Epoch 3/50\n",
      "1202/1202 [==============================] - 1s 1ms/step - loss: 0.6931 - acc: 0.5474 - val_loss: 0.6875 - val_acc: 0.5586\n",
      "Epoch 4/50\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.6886 - acc: 0.5599 - val_loss: 0.6866 - val_acc: 0.5561\n",
      "Epoch 5/50\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.6864 - acc: 0.5632 - val_loss: 0.6851 - val_acc: 0.5586\n",
      "Epoch 6/50\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.6857 - acc: 0.5557 - val_loss: 0.6849 - val_acc: 0.5636\n",
      "Epoch 7/50\n",
      "1202/1202 [==============================] - 1s 1ms/step - loss: 0.6891 - acc: 0.5632 - val_loss: 0.6851 - val_acc: 0.5636\n",
      "Epoch 8/50\n",
      "1202/1202 [==============================] - 2s 2ms/step - loss: 0.6891 - acc: 0.5591 - val_loss: 0.6859 - val_acc: 0.5636\n",
      "Epoch 9/50\n",
      "1202/1202 [==============================] - 2s 2ms/step - loss: 0.6834 - acc: 0.5599 - val_loss: 0.6857 - val_acc: 0.5636\n",
      "Epoch 10/50\n",
      "1202/1202 [==============================] - 2s 2ms/step - loss: 0.6828 - acc: 0.5582 - val_loss: 0.6847 - val_acc: 0.5636\n",
      "Epoch 11/50\n",
      "1202/1202 [==============================] - 2s 2ms/step - loss: 0.6867 - acc: 0.5599 - val_loss: 0.6839 - val_acc: 0.5636\n",
      "Epoch 12/50\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.6779 - acc: 0.5707 - val_loss: 0.6732 - val_acc: 0.5636\n",
      "Epoch 13/50\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.6683 - acc: 0.5641 - val_loss: 0.6666 - val_acc: 0.5586\n",
      "Epoch 14/50\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.6530 - acc: 0.5840 - val_loss: 0.6616 - val_acc: 0.5636\n",
      "Epoch 15/50\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.6233 - acc: 0.6090 - val_loss: 0.6592 - val_acc: 0.5611\n",
      "Epoch 16/50\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.6095 - acc: 0.6223 - val_loss: 0.6548 - val_acc: 0.6010\n",
      "Epoch 17/50\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.5856 - acc: 0.6839 - val_loss: 0.6563 - val_acc: 0.6284\n",
      "Epoch 18/50\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.5592 - acc: 0.6905 - val_loss: 0.6693 - val_acc: 0.6209\n",
      "Epoch 19/50\n",
      "1202/1202 [==============================] - 2s 2ms/step - loss: 0.5360 - acc: 0.7221 - val_loss: 0.6536 - val_acc: 0.6135\n",
      "Epoch 20/50\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.5063 - acc: 0.7587 - val_loss: 0.6675 - val_acc: 0.6010\n",
      "Epoch 21/50\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.4838 - acc: 0.7704 - val_loss: 0.7866 - val_acc: 0.6160\n",
      "Epoch 22/50\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.4949 - acc: 0.7671 - val_loss: 0.7072 - val_acc: 0.6060\n",
      "Epoch 23/50\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.4727 - acc: 0.7795 - val_loss: 0.7787 - val_acc: 0.6185\n",
      "Epoch 24/50\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.4779 - acc: 0.7887 - val_loss: 0.7391 - val_acc: 0.6035\n",
      "Epoch 25/50\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.4491 - acc: 0.7937 - val_loss: 0.8727 - val_acc: 0.5910\n",
      "Epoch 26/50\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.4513 - acc: 0.7820 - val_loss: 0.8057 - val_acc: 0.6035\n",
      "Epoch 27/50\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.4355 - acc: 0.8012 - val_loss: 0.8124 - val_acc: 0.5935\n",
      "Epoch 28/50\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.4495 - acc: 0.8028 - val_loss: 0.8666 - val_acc: 0.6160\n",
      "Epoch 29/50\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.4330 - acc: 0.8028 - val_loss: 0.8585 - val_acc: 0.5985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b0a43a90>"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit([wv_train, sim_train], y_train,\n",
    "          epochs=50, batch_size=64, class_weight=y_train, validation_data = (\n",
    "              {'main_input': wv_val, 'aux_input': sim_val}, {'main_output': y_val}\n",
    "          ), callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1202/1202 [==============================] - 1s 574us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3595322126060873, 0.8594009984352823]"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate([wv_train, sim_train], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401/401 [==============================] - 0s 550us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8584535784852177, 0.5985037407226991]"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate([wv_val, sim_val], y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[115 110]\n",
      " [ 51 125]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.51      0.59       225\n",
      "          1       0.53      0.71      0.61       176\n",
      "\n",
      "avg / total       0.62      0.60      0.60       401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_val, (model2.predict([wv_val, sim_val]).reshape(-1)>.5).astype(int)))\n",
    "print(classification_report(y_val, (model2.predict([wv_val, sim_val]).reshape(-1)>.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401/401 [==============================] - 0s 511us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8790594981495579, 0.6134663349077886]"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate([wv_test, sim_test], y_test)s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 96 130]\n",
      " [ 70 105]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.42      0.49       226\n",
      "          1       0.45      0.60      0.51       175\n",
      "\n",
      "avg / total       0.52      0.50      0.50       401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, (model2.predict([wv_val, sim_test]).reshape(-1)>.5).astype(int)))\n",
    "print(classification_report(y_test, (model2.predict([wv_val, sim_test]).reshape(-1)>.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2.save('lstm2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
